<!DOCTYPE html>
<html lang="">

<head>
	<meta name="generator" content="Hugo 0.62.0" />
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="author" content="TristonK ">
<meta name="description" content="对应章节：《Reinforcement Learning: An Introduction》第二版 Chap 5 蒙特卡洛方法不需要环境的信息，只需要经验（experience" />
<meta name="keywords" content="blog" />
<meta name="robots" content="noodp" />

<link rel="canonical" href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl5/" />

<meta itemprop="name" content="Monte Carlo Methods">
<meta itemprop="description" content="对应章节：《Reinforcement Learning: An Introduction》第二版 Chap 5 蒙特卡洛方法不需要环境的信息，只需要经验（experience">

<meta itemprop="wordCount" content="1783">



<meta itemprop="keywords" content="" />
<meta property="og:title" content="Monte Carlo Methods" />
<meta property="og:description" content="对应章节：《Reinforcement Learning: An Introduction》第二版 Chap 5 蒙特卡洛方法不需要环境的信息，只需要经验（experience" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl5/" />


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Monte Carlo Methods"/>
<meta name="twitter:description" content="对应章节：《Reinforcement Learning: An Introduction》第二版 Chap 5 蒙特卡洛方法不需要环境的信息，只需要经验（experience"/>


<link rel="apple-touch-icon" sizes="60x60" href="http://tristonk.com/icons/favi60.jpg">
<link rel="icon" type="image/jpg" sizes="32x32" href="http://tristonk.com/icons/favi32.jpg">
<link rel="icon" type="image/jpg" sizes="16x16" href="http://tristonk.com/icons/favi16.jpg">
<link rel="manifest" href="http://tristonk.com/icons/site.webmanifest">
<link rel="mask-icon" href="http://tristonk.com/icons/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="http://tristonk.com/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-config" content="/icons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">

<title>Monte Carlo Methods</title>


<link rel="stylesheet" href="//at.alicdn.com/t/font_1604402_jsamxf8dml9.css">


    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">



    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.css" integrity="sha256-WAgYcAck1C1/zEl5sBl5cfyhxtLgKGdpI3oKyJffVRI=" crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.2/animate.css" integrity="sha256-a2tobsqlbgLsWs7ZVUGgP5IvWZsx8bTNQpzsqCSm5mk=" crossorigin="anonymous" />
    
   <link href="https://stackpath.bootstrapcdn.com/bootswatch/4.4.1/materia/bootstrap.min.css" rel="stylesheet" integrity="sha384-1tymk6x9Y5K+OF0tlmG2fDRcn67QGzBkiM3IgtJ3VrtGrIi5ryhHjKjeeS60f1FA" crossorigin="anonymous">
    
    
    <link rel="stylesheet" href="http://tristonk.com/sass/main_cdn.min.b8209e60e6fa71b6aea68f9916efec89f754f9bfce454534a6e19c19243024c5.min.b14128c186a32f49f813b7eb9d1fa95180bf2223b331355b837b07e1f81bbeb1.css" integity="sha256-sUEowYajL0n4E7frnR&#43;pUYC/IiOzMTVbg3sH4fgbvrE=">


<script data-ad-client="pub-2356829494971208" async src="https://pagead2.googlesyndication.com/
pagead/js/adsbygoogle.js"></script>
</head>

<body style="overflow-x: unset;">
	<div class="container-fluid">
		<div class="row d-print-block">
			<div class="col-12 col-md-3 col-lg-2 bd-sidebar d-print-none">
				<div class="d-flex mt-3 border-bottom">
        <span class="navbar-brand w-100" style="display: grid;">
            <small>
                <a href="http://tristonk.com/" class="text-black-50">
                    <i class="iconfont icon-back-arrow-"></i>
                </a>
                TristonK's
            </small>
            <a class="text-dark" href="http://tristonk.com/notes/">
                Notes
            </a>
        </span>
        <button class="btn btn-link text-dark d-md-none p-0 ml-3" type="button" data-toggle="collapse"
            data-target="#bd-docs-nav" aria-controls="bd-docs-nav" aria-expanded="true"
            aria-label="Toggle docs navigation">
            <i class="fad fa-bars"></i>
        </button>
    </div>
				<nav id="bd-docs-nav" class="collapse bd-links">
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/google%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/">
            
            
            
            Google代码规范
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A33/">
            
            
            
            问题求解（三）
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A34/">
            
            
            
            问题求解（四）
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">
            
            
            
            操作系统
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E7%A7%81%E4%BA%BA%E7%94%9F%E6%B4%BB%E7%9A%84%E5%8F%98%E9%9D%A9/">
            
            
            
            私人生活的变革
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E5%BE%AE%E7%94%B5%E5%AD%90%E4%B8%8E%E7%94%B5%E8%B7%AF/">
            
            
            
            微电子与电路
        </a>
    </div>
    
    
    
    <div class="bd-toc-item active bg-light">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">
            <i class="iconfont icon-back-arrow-reverse"></i>
            强化学习
        </a>
        <ul class="nav bd-sidenav">
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl2/">Multi-armed Bandits</a>
            </li>
            
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl3/">Finite Markov Decision Processes</a>
            </li>
            
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl4/">Dynamic Programming</a>
            </li>
            
            
            
            <li class="active">
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl5/">
                    <i class="fad fa-chevron-right mr-1"></i>
                    Monte Carlo Methods
                </a>
            </li>
            
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl6/">Temporal-Difference Learning</a>
            </li>
            
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/rl7/">n-step Bootstraping</a>
            </li>
            
            
            
            <li>
                <a href="http://tristonk.com/notes/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A01/">强化学习-介绍</a>
            </li>
            
            
        </ul>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E7%A4%BE%E4%BC%9A%E5%AD%A6%E6%A6%82%E8%AE%BA/">
            
            
            
            社会学概论
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/">
            
            
            
            组合数学
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%AE%BA/">
            
            
            
            数据库概论
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">
            
            
            
            计算机网络
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/csmissingsemester/">
            
                <i class="iconfont icon-target"></i>
            
            CSMissing
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E6%94%BF%E6%B2%BB%E5%AD%A6%E9%80%9A%E8%AF%86/">
            
                <i class="iconfont icon-target"></i>
            
            政治学通识
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
            
                <i class="iconfont icon-target"></i>
            
            机器学习
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/compiler/">
            
                <i class="iconfont icon-target"></i>
            
            编译原理
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E8%BD%AF%E4%BB%B6%E5%88%86%E6%9E%90/">
            
                <i class="iconfont icon-target"></i>
            
            软件分析
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E4%BC%9F%E5%A4%A7%E4%BC%A0%E7%BB%9F%E7%B3%BB%E5%88%97-%E5%8D%8E%E5%A4%8F%E5%87%BA%E7%89%88%E7%A4%BE/">
            
            
            
            伟大传统系列
        </a>
    </div>
    
    
    
    <div class="bd-toc-item">
        <a class="bd-toc-link" href="http://tristonk.com/notes/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">
            
                <i class="iconfont icon-target"></i>
            
            数据挖掘导论
        </a>
    </div>
    
    
</nav>
			</div>
			<div class="col-12 col-md-9 col-lg-10 d-print-block">
				<div class="row d-print-block">
					<main class="col-12 col-md-10 col-lg-9 py-md-3 pl-md-5 bd-content d-print-block" role="main">
						<div id="title" class="my-4 border-bottom">
							<span>强化学习</span>
							<h2>Monte Carlo Methods</h2>
							<footer>
								<span>
									<i class="iconfont icon-NewFile mr-2"></i>
									0001-01-01 08:00 CST
								</span> <br />
								<span>
									<i class="iconfont icon-modify mr-2"></i>
									0001-01-01 08:00 CST
								</span> <br />
								<span>
									<i class="iconfont icon-copyright mr-2"></i>
									CC BY-NC 4.0
								</span>
							</footer>
						</div>
						<div id="content" class="hl-h2">
							
							
							
							
							
							
							
							
							
							
							
							
							<blockquote>
<p>对应章节：<a href="http://www.incompleteideas.net/book/the-book-2nd.html">《Reinforcement Learning: An Introduction》第二版</a>  Chap 5</p>
</blockquote>
<p>蒙特卡洛方法不需要环境的信息，只需要经验（experience—sample sequences of states, actions, and rewards from actual or simulated interaction with an environment.）</p>
<p>Monte Carlo methods are ways of solving the reinforcement learning problem based on averaging sample returns. To ensure that well-defined returns are available, here we define Monte Carlo methods only for episodic tasks.</p>
<h2 id="51-monte-carlo-prediction">5.1 Monte Carlo Prediction<a href="#51-monte-carlo-prediction" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<p>有两种方法，一种是“<strong><code>first-visit</code></strong>“,把整个片段集所有第一次访问到状态<img src="https://www.zhihu.com/equation?tex=s" alt="[公式]">时的returns做平均化处理，来估计$v_\pi(s)$的值另一种是”<strong><code>every visit</code></strong>”，把整个片段集中所有访问到s状态时的returns取平均，来估计$v_\pi(s)$的值。两种方法都有应用，下给出first-visit，在9和12章介绍every-visit</p>
<img src="../rl5/51.png">
<p>每一次返回平均值都是其本身的无偏估计，标准偏差在$\sqrt{\frac{1}{n}}$内</p>
<p>蒙特卡洛算法每一次运行都是独立的，也就是说他不是&quot;bootstrap&quot;的</p>
<h2 id="52-monte-carlo-estimation-of-action-values">5.2 Monte Carlo Estimation of Action Values<a href="#52-monte-carlo-estimation-of-action-values" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<p>如何估计$q_\pi(s,a)$, 同上一小节一样也是first-visit与every-visit两种方式</p>
<p>不过有一个问题在于如何保证所有的action都被考虑到，这就是之前第二章提到的如何保持exploit和explore的关系的问题，称为“<strong><code>maintaining exloration</code></strong>“问题，一种解决方式是对于每一个state–action pair，都给予其一定的概率作为一个episode的起点，这样当取样次数趋于无限的时候，每一个pair的取样次数也趋于无限了，这种方式的假设称为<strong><code>exploring starts</code></strong>.
但是这样有一个问题就是&quot;it cannot be relied upon in general, particularly when learning directly from actual interaction with an environment.&quot;, 此时一种常见的策略是调整policy，使得对于一个状态，所有的action都有一定的概率发生</p>
<h2 id="53-monte-carlo-control">5.3 Monte Carlo Control<a href="#53-monte-carlo-control" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<p>蒙特卡洛方法估计最优policies的方法和DP差不多：先迭代value function使之逼近当前policy的真实value function，然后基于更新后的value function进行policy improvement，直到最终policy基本不再变化</p>
<img src="../rl5/52.png">
<p>由于我们在此处估计的是$q_\pi(s,a)$，就不需要额外的model来确定最优的action了，可以直接根据$\pi(s)=\arg \max_a q(s, a)$来确定</p>
<p>为了更具备实际意义，我们要考虑如何去掉infinte number of episodes 的假设 ，一种方式是设立一个极小值，当两次policy evaluation的差别小于这个值的时候，认为此次policy evaluation结束，这种方式在小规模情况下很好，但是数据规模较大时仍然会需要比较多次。另一种方式就是放弃完整的policy evaluation，类似于4.6中的value  iteration</p>
<p>以下算法仍然基于了exploring starts 假设</p>
<img src="../rl5/53.png">
<h2 id="54-monte-carlo-control-without-exploring-starts">5.4 Monte Carlo Control without Exploring Starts<a href="#54-monte-carlo-control-without-exploring-starts" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<p><strong><code>on-policy</code></strong>: 直接优化或评价目标策略</p>
<p>对于on-policy策略而言，对于所有的pair有$\pi(a|s) \ge \frac{\varepsilon}{|\mathcal A(s)|}$</p>
<p>采取第二章中提到的类似的方法，以$p= 1- \varepsilon + \frac{\varepsilon}{|\mathcal A(s)|}$的概率选取原先确定的action</p>
<img src="../rl5/54.png">
<p><del>此处省略一大段，如果有兴趣看相关证明的可以自己看书</del></p>
<h2 id="55-off-policy-prediction-via-importance-sampling">5.5 Off-policy Prediction via Importance Sampling<a href="#55-off-policy-prediction-via-importance-sampling" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<p>在on-policy中，由于我们需要explore所有的action，这也就导致我们在一些时候会选择非最优的情况，故而我们有了off-policy的想法</p>
<p><strong><code>off-policy</code></strong>: 有两个策略，一个叫行为策略 $b$（behavior policy），另一个叫做目标策略$\pi$（target policy），从behavior policy生成的episodes中学习target policy的过程，叫做off-policy learning。</p>
<blockquote>
<p>关于off-policy与on-policy的应用比较</p>
<p>Throughout the rest of this book we consider both on-policy and off-policy methods. On-policy methods are generally simpler and are considered first. Off-policy methods require additional concepts and notation, and because the data is due to a di↵erent policy, off-policy methods are often of greater variance and are slower to converge. On the other hand, off-policy methods are more powerful and general.They include on-policy methods as the special case in which the target and behavior policies are the same. Off-policy methods also have a variety of additional uses in applications. For example, they can often be applied to learn from data generated by a conventional non-learning controller, or from a human expert. Off-policy learning is also seen by some as key to learning multi-step predictive models of the world’s dynamics</p>
</blockquote>
<p><del>下面又是一大波我不想看的数学知识</del></p>
<p>TODO()<del>以后一定补</del></p>
<p>因此有两种方式，可以取：</p>
<p>一种是取平均（ordinary importance sampling）</p>
<p>$$V(s) = \frac{\sum_{t \in \mathcal T(s)} \rho_t G_t}{|\mathcal T(s)|}$$</p>
<p>另一种是加权平均（weighted average）</p>
<p>$$V(s) = \frac{\sum_{t \in \mathcal T(s)} \rho_t G_t}{\sum_{t \in \mathcal T(s)} \rho_t}$$</p>
<h2 id="56-incremental-implementation">5.6 Incremental Implementation<a href="#56-incremental-implementation" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<img src="../rl5/55.png">
<h2 id="57-off-policy-monte-carlo-control">5.7 Off-policy Monte Carlo Control<a href="#57-off-policy-monte-carlo-control" class="anchor" aria-hidden="true"><i class="iconfont icon-link"></i></a></h2>
<img src="../rl5/56.png">
						</div>
					</main>
					<div class="d-none d-lg-block col-lg-3 bd-toc d-print-none">
						<div class="btn-group-vertical w-100 my-3">
    
    <a class="btn btn-outline-secondary text-dark w-100 p-2" href="https://github.com/shelah-kuang/shelah-kuang.github.io/issues" target="_blank">
        <i class="iconfont icon-LC_icon_list_line"></i><br />待更新列表
    </a>
    

    
    <a class="btn btn-outline-secondary text-dark w-100 p-2" href="mailto:kuangsl@foxmail.com"
        target="_blank">
        <i class="iconfont icon-discussion"></i><br />纠错与咨询
    </a>
    
    
    
    
        <a class="btn btn-outline-secondary text-dark w-100 p-2" href="#" onclick="window.print()">
            <i class="iconfont icon-dayin"></i><br />打印本页
        </a>
    
    
</div>
						<h4 class="card-title pb-0">目录</h4>
						<nav id="TableOfContents">
  <ul>
    <li><a href="#51-monte-carlo-prediction">5.1 Monte Carlo Prediction</a></li>
    <li><a href="#52-monte-carlo-estimation-of-action-values">5.2 Monte Carlo Estimation of Action Values</a></li>
    <li><a href="#53-monte-carlo-control">5.3 Monte Carlo Control</a></li>
    <li><a href="#54-monte-carlo-control-without-exploring-starts">5.4 Monte Carlo Control without Exploring Starts</a></li>
    <li><a href="#55-off-policy-prediction-via-importance-sampling">5.5 Off-policy Prediction via Importance Sampling</a></li>
    <li><a href="#56-incremental-implementation">5.6 Incremental Implementation</a></li>
    <li><a href="#57-off-policy-monte-carlo-control">5.7 Off-policy Monte Carlo Control</a></li>
  </ul>
</nav>
						
						
					</div>
				</div>
			</div>
		</div>
	</div>

	<script
    src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
onload="renderMathInElement(document.body);"></script>

<script type="text/javascript" src="http://tristonk.com/custom.min.d3e1b7647f32dbe7e0140398739a26dad3f3470fc1eebe0741ef33668f1b7bd0b2917dc6efb9f0d9f1092b91dca502cab1b883863f02530133a8a8ef609926af.js" integrity="sha512-0&#43;G3ZH8y2&#43;fgFAOYc5om2tPzRw/B7r4HQe8zZo8be9CykX3G77nw2fEJK5HcpQLKsbiDhj8CUwEzqKjvYJkmrw=="></script>
<script type="text/javascript">

document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(
        document.body, {
            delimiters: [
                {
                    left: "$$",
                    right: "$$",
                    display: true
                },
                {
                    left: "\\[",
                    right: "\\]",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                },
                {
                    left: "\\(",
                    right: "\\)",
                    display: false
                }
            ],
            strict: false
        }
    );
});


$(document).on('click', 'a[href^="#"]', function (event) {
    event.preventDefault();

    $('html, body').animate({
        scrollTop: $($.attr(this, 'href')).offset().top
    }, 500);
});
</script>




</body>

</html>